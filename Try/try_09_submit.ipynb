{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017e9265",
   "metadata": {},
   "source": [
    "# 영업 성공 여부 분류 경진대회"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdab431",
   "metadata": {},
   "source": [
    "## 1. 데이터 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8341e8",
   "metadata": {},
   "source": [
    "### 필수 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e590e251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in ./.local/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in ./.local/lib/python3.10/site-packages (from seaborn) (1.23.5)\n",
      "Requirement already satisfied: pandas>=1.2 in ./.local/lib/python3.10/site-packages (from seaborn) (2.1.4)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in ./.local/lib/python3.10/site-packages (from seaborn) (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in ./.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.local/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.local/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in ./.local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: miceforest in ./.local/lib/python3.10/site-packages (5.7.0)\n",
      "Requirement already satisfied: lightgbm>=3.3.1 in ./.local/lib/python3.10/site-packages (from miceforest) (3.3.2)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.10/site-packages (from miceforest) (1.23.5)\n",
      "Requirement already satisfied: blosc in ./.local/lib/python3.10/site-packages (from miceforest) (1.11.1)\n",
      "Requirement already satisfied: dill in ./.local/lib/python3.10/site-packages (from miceforest) (0.3.8)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.10/site-packages (from lightgbm>=3.3.1->miceforest) (0.41.3)\n",
      "Requirement already satisfied: scipy in ./.local/lib/python3.10/site-packages (from lightgbm>=3.3.1->miceforest) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in ./.local/lib/python3.10/site-packages (from lightgbm>=3.3.1->miceforest) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./.local/lib/python3.10/site-packages (from scikit-learn!=0.22.0->lightgbm>=3.3.1->miceforest) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.local/lib/python3.10/site-packages (from scikit-learn!=0.22.0->lightgbm>=3.3.1->miceforest) (3.2.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: fancyimpute in ./.local/lib/python3.10/site-packages (0.7.0)\n",
      "Requirement already satisfied: knnimpute>=0.1.0 in ./.local/lib/python3.10/site-packages (from fancyimpute) (0.1.0)\n",
      "Requirement already satisfied: scikit-learn>=0.24.2 in ./.local/lib/python3.10/site-packages (from fancyimpute) (1.2.2)\n",
      "Requirement already satisfied: cvxpy in ./.local/lib/python3.10/site-packages (from fancyimpute) (1.4.2)\n",
      "Requirement already satisfied: cvxopt in ./.local/lib/python3.10/site-packages (from fancyimpute) (1.3.2)\n",
      "Requirement already satisfied: pytest in ./.local/lib/python3.10/site-packages (from fancyimpute) (8.0.0)\n",
      "Requirement already satisfied: nose in ./.local/lib/python3.10/site-packages (from fancyimpute) (1.3.7)\n",
      "Requirement already satisfied: six in ./.local/lib/python3.10/site-packages (from knnimpute>=0.1.0->fancyimpute) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.10 in ./.local/lib/python3.10/site-packages (from knnimpute>=0.1.0->fancyimpute) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in ./.local/lib/python3.10/site-packages (from scikit-learn>=0.24.2->fancyimpute) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./.local/lib/python3.10/site-packages (from scikit-learn>=0.24.2->fancyimpute) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.local/lib/python3.10/site-packages (from scikit-learn>=0.24.2->fancyimpute) (3.2.0)\n",
      "Requirement already satisfied: osqp>=0.6.2 in ./.local/lib/python3.10/site-packages (from cvxpy->fancyimpute) (0.6.5)\n",
      "Requirement already satisfied: ecos>=2 in ./.local/lib/python3.10/site-packages (from cvxpy->fancyimpute) (2.0.12)\n",
      "Requirement already satisfied: clarabel>=0.5.0 in ./.local/lib/python3.10/site-packages (from cvxpy->fancyimpute) (0.6.0)\n",
      "Requirement already satisfied: scs>=3.0 in ./.local/lib/python3.10/site-packages (from cvxpy->fancyimpute) (3.2.4.post1)\n",
      "Requirement already satisfied: pybind11 in ./.local/lib/python3.10/site-packages (from cvxpy->fancyimpute) (2.11.1)\n",
      "Requirement already satisfied: iniconfig in ./.local/lib/python3.10/site-packages (from pytest->fancyimpute) (2.0.0)\n",
      "Requirement already satisfied: packaging in ./.local/lib/python3.10/site-packages (from pytest->fancyimpute) (23.2)\n",
      "Requirement already satisfied: pluggy<2.0,>=1.3.0 in ./.local/lib/python3.10/site-packages (from pytest->fancyimpute) (1.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in ./.local/lib/python3.10/site-packages (from pytest->fancyimpute) (1.2.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in ./.local/lib/python3.10/site-packages (from pytest->fancyimpute) (2.0.1)\n",
      "Requirement already satisfied: qdldl in ./.local/lib/python3.10/site-packages (from osqp>=0.6.2->cvxpy->fancyimpute) (0.1.7.post0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: missingno in ./.local/lib/python3.10/site-packages (0.5.2)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.10/site-packages (from missingno) (1.23.5)\n",
      "Requirement already satisfied: matplotlib in ./.local/lib/python3.10/site-packages (from missingno) (3.8.2)\n",
      "Requirement already satisfied: scipy in ./.local/lib/python3.10/site-packages (from missingno) (1.11.4)\n",
      "Requirement already satisfied: seaborn in ./.local/lib/python3.10/site-packages (from missingno) (0.13.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.local/lib/python3.10/site-packages (from matplotlib->missingno) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.local/lib/python3.10/site-packages (from matplotlib->missingno) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.local/lib/python3.10/site-packages (from matplotlib->missingno) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.local/lib/python3.10/site-packages (from matplotlib->missingno) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.10/site-packages (from matplotlib->missingno) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in ./.local/lib/python3.10/site-packages (from matplotlib->missingno) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.local/lib/python3.10/site-packages (from matplotlib->missingno) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.local/lib/python3.10/site-packages (from matplotlib->missingno) (2.8.2)\n",
      "Requirement already satisfied: pandas>=1.2 in ./.local/lib/python3.10/site-packages (from seaborn->missingno) (2.1.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.local/lib/python3.10/site-packages (from pandas>=1.2->seaborn->missingno) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.local/lib/python3.10/site-packages (from pandas>=1.2->seaborn->missingno) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in ./.local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->missingno) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: hyperopt in ./.local/lib/python3.10/site-packages (0.2.7)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.10/site-packages (from hyperopt) (1.23.5)\n",
      "Requirement already satisfied: scipy in ./.local/lib/python3.10/site-packages (from hyperopt) (1.11.4)\n",
      "Requirement already satisfied: six in ./.local/lib/python3.10/site-packages (from hyperopt) (1.16.0)\n",
      "Requirement already satisfied: networkx>=2.2 in ./.local/lib/python3.10/site-packages (from hyperopt) (3.0)\n",
      "Requirement already satisfied: future in ./.local/lib/python3.10/site-packages (from hyperopt) (0.18.3)\n",
      "Requirement already satisfied: tqdm in ./.local/lib/python3.10/site-packages (from hyperopt) (4.66.1)\n",
      "Requirement already satisfied: cloudpickle in ./.local/lib/python3.10/site-packages (from hyperopt) (3.0.0)\n",
      "Requirement already satisfied: py4j in ./.local/lib/python3.10/site-packages (from hyperopt) (0.10.9.7)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bayesian-optimization in ./.local/lib/python3.10/site-packages (1.4.3)\n",
      "Requirement already satisfied: numpy>=1.9.0 in ./.local/lib/python3.10/site-packages (from bayesian-optimization) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.0.0 in ./.local/lib/python3.10/site-packages (from bayesian-optimization) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in ./.local/lib/python3.10/site-packages (from bayesian-optimization) (1.2.2)\n",
      "Requirement already satisfied: colorama>=0.4.6 in ./.local/lib/python3.10/site-packages (from bayesian-optimization) (0.4.6)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./.local/lib/python3.10/site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.local/lib/python3.10/site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn\n",
    "!pip install miceforest\n",
    "!pip install fancyimpute\n",
    "!pip install missingno\n",
    "!pip install hyperopt\n",
    "!pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8992e1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import matplotlib as mpl\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "\n",
    "from hyperopt import hp\n",
    "from hyperopt import STATUS_OK\n",
    "from hyperopt import fmin, tpe, Trials\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from fancyimpute import IterativeImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "import miceforest as mf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412f98cc",
   "metadata": {},
   "source": [
    "### 데이터 셋 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ada941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\") # 학습용 데이터\n",
    "df_test = pd.read_csv(\"submission.csv\") # 테스트 데이터(제출파일의 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be9af12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bant_submit</th>\n",
       "      <th>customer_country</th>\n",
       "      <th>business_unit</th>\n",
       "      <th>com_reg_ver_win_rate</th>\n",
       "      <th>customer_idx</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>enterprise</th>\n",
       "      <th>historical_existing_cnt</th>\n",
       "      <th>id_strategic_ver</th>\n",
       "      <th>it_strategic_ver</th>\n",
       "      <th>idit_strategic_ver</th>\n",
       "      <th>customer_job</th>\n",
       "      <th>lead_desc_length</th>\n",
       "      <th>inquiry_type</th>\n",
       "      <th>product_category</th>\n",
       "      <th>product_subcategory</th>\n",
       "      <th>product_modelname</th>\n",
       "      <th>customer_country.1</th>\n",
       "      <th>customer_position</th>\n",
       "      <th>response_corporate</th>\n",
       "      <th>expected_timeline</th>\n",
       "      <th>ver_cus</th>\n",
       "      <th>ver_pro</th>\n",
       "      <th>ver_win_rate_x</th>\n",
       "      <th>ver_win_ratio_per_bu</th>\n",
       "      <th>business_area</th>\n",
       "      <th>business_subarea</th>\n",
       "      <th>lead_owner</th>\n",
       "      <th>is_converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>/Quezon City/Philippines</td>\n",
       "      <td>AS</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>32160</td>\n",
       "      <td>End-Customer</td>\n",
       "      <td>Enterprise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>purchasing</td>\n",
       "      <td>62</td>\n",
       "      <td>Quotation or purchase consultation</td>\n",
       "      <td>multi-split</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Quezon City/Philippines</td>\n",
       "      <td>entry level</td>\n",
       "      <td>LGEPH</td>\n",
       "      <td>less than 3 months</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>0.026846</td>\n",
       "      <td>corporate / office</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>/PH-00/Philippines</td>\n",
       "      <td>AS</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>23122</td>\n",
       "      <td>End-Customer</td>\n",
       "      <td>Enterprise</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>media and communication</td>\n",
       "      <td>96</td>\n",
       "      <td>Quotation or purchase consultation</td>\n",
       "      <td>multi-split</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/PH-00/Philippines</td>\n",
       "      <td>ceo/founder</td>\n",
       "      <td>LGEPH</td>\n",
       "      <td>less than 3 months</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>0.026846</td>\n",
       "      <td>corporate / office</td>\n",
       "      <td>Advertising</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>/Kolkata /India</td>\n",
       "      <td>AS</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>1755</td>\n",
       "      <td>End-Customer</td>\n",
       "      <td>Enterprise</td>\n",
       "      <td>144.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>engineering</td>\n",
       "      <td>56</td>\n",
       "      <td>Product Information</td>\n",
       "      <td>single-split</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Kolkata /India</td>\n",
       "      <td>partner</td>\n",
       "      <td>LGEIL</td>\n",
       "      <td>less than 3 months</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>0.026846</td>\n",
       "      <td>corporate / office</td>\n",
       "      <td>Construction</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>/Bhubaneswar/India</td>\n",
       "      <td>AS</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>4919</td>\n",
       "      <td>End-Customer</td>\n",
       "      <td>Enterprise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>entrepreneurship</td>\n",
       "      <td>44</td>\n",
       "      <td>Quotation or purchase consultation</td>\n",
       "      <td>vrf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Bhubaneswar/India</td>\n",
       "      <td>ceo/founder</td>\n",
       "      <td>LGEIL</td>\n",
       "      <td>less than 3 months</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>0.026846</td>\n",
       "      <td>corporate / office</td>\n",
       "      <td>IT/Software</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>/Hyderabad/India</td>\n",
       "      <td>AS</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>17126</td>\n",
       "      <td>Specifier/ Influencer</td>\n",
       "      <td>Enterprise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>consulting</td>\n",
       "      <td>97</td>\n",
       "      <td>Quotation or purchase consultation</td>\n",
       "      <td>multi-split</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Hyderabad/India</td>\n",
       "      <td>partner</td>\n",
       "      <td>LGEIL</td>\n",
       "      <td>less than 3 months</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>0.026846</td>\n",
       "      <td>corporate / office</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bant_submit          customer_country business_unit  com_reg_ver_win_rate  \\\n",
       "0          1.0  /Quezon City/Philippines            AS              0.066667   \n",
       "1          1.0        /PH-00/Philippines            AS              0.066667   \n",
       "2          1.0           /Kolkata /India            AS              0.088889   \n",
       "3          1.0        /Bhubaneswar/India            AS              0.088889   \n",
       "4          1.0          /Hyderabad/India            AS              0.088889   \n",
       "\n",
       "   customer_idx          customer_type  enterprise  historical_existing_cnt  \\\n",
       "0         32160           End-Customer  Enterprise                      NaN   \n",
       "1         23122           End-Customer  Enterprise                     12.0   \n",
       "2          1755           End-Customer  Enterprise                    144.0   \n",
       "3          4919           End-Customer  Enterprise                      NaN   \n",
       "4         17126  Specifier/ Influencer  Enterprise                      NaN   \n",
       "\n",
       "   id_strategic_ver  it_strategic_ver  idit_strategic_ver  \\\n",
       "0               NaN               NaN                 NaN   \n",
       "1               NaN               NaN                 NaN   \n",
       "2               NaN               NaN                 NaN   \n",
       "3               NaN               NaN                 NaN   \n",
       "4               NaN               NaN                 NaN   \n",
       "\n",
       "              customer_job  lead_desc_length  \\\n",
       "0               purchasing                62   \n",
       "1  media and communication                96   \n",
       "2              engineering                56   \n",
       "3         entrepreneurship                44   \n",
       "4               consulting                97   \n",
       "\n",
       "                         inquiry_type product_category product_subcategory  \\\n",
       "0  Quotation or purchase consultation      multi-split                 NaN   \n",
       "1  Quotation or purchase consultation      multi-split                 NaN   \n",
       "2                 Product Information     single-split                 NaN   \n",
       "3  Quotation or purchase consultation              vrf                 NaN   \n",
       "4  Quotation or purchase consultation      multi-split                 NaN   \n",
       "\n",
       "  product_modelname        customer_country.1 customer_position  \\\n",
       "0               NaN  /Quezon City/Philippines       entry level   \n",
       "1               NaN        /PH-00/Philippines       ceo/founder   \n",
       "2               NaN           /Kolkata /India           partner   \n",
       "3               NaN        /Bhubaneswar/India       ceo/founder   \n",
       "4               NaN          /Hyderabad/India           partner   \n",
       "\n",
       "  response_corporate   expected_timeline  ver_cus  ver_pro  ver_win_rate_x  \\\n",
       "0              LGEPH  less than 3 months        1        0        0.003079   \n",
       "1              LGEPH  less than 3 months        1        0        0.003079   \n",
       "2              LGEIL  less than 3 months        1        0        0.003079   \n",
       "3              LGEIL  less than 3 months        1        0        0.003079   \n",
       "4              LGEIL  less than 3 months        0        0        0.003079   \n",
       "\n",
       "   ver_win_ratio_per_bu       business_area business_subarea  lead_owner  \\\n",
       "0              0.026846  corporate / office      Engineering           0   \n",
       "1              0.026846  corporate / office      Advertising           1   \n",
       "2              0.026846  corporate / office     Construction           2   \n",
       "3              0.026846  corporate / office      IT/Software           3   \n",
       "4              0.026846  corporate / office              NaN           4   \n",
       "\n",
       "   is_converted  \n",
       "0          True  \n",
       "1          True  \n",
       "2          True  \n",
       "3          True  \n",
       "4          True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head() # 학습용 데이터 살펴보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af526c13",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "304e9bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['ver_country'] = df_train['com_reg_ver_win_rate'] / df_train['ver_win_ratio_per_bu']\n",
    "df_test['ver_country'] = df_test['com_reg_ver_win_rate'] / df_test['ver_win_ratio_per_bu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42404458",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['product_category'] = df_train['product_category'].str.lower().str.replace(\" \", \"\")\n",
    "df_test['product_category'] = df_test['product_category'].str.lower().str.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "759671ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_mapping = { 'HVAC/ESS': ['control', 'ventilation', 'vrf', 'multi-split', 'arcondicionadoresidencial','single-split', 'chiler','chiller', 'heating','rac','tetooucasseteinverter','multiinverter'],\n",
    "                     'Commercial Display': ['interactivedigitalboard','oledsignage', 'ledsignage', 'videowallsignage', 'videowall','interactivesignage', 'highbrightnesssignage','highbrightness', 'specialsignage', 'standardsignage', 'hoteltv', 'hospitaltv', 'softwaresolution', 'signagecaresolution', 'lgone:quickseries','accessories', 'webos', 'one:quickseries', 'pro:centric'],\n",
    "                      'IT PRODUCTS': ['monitor', 'laptop', 'projector','pc', 'clouddevice', 'medicaldisplay'], \n",
    "                      'Commerical Laundry': ['titan(largecapacity)', 'giant(standardcapacity)'],\n",
    "                      'Compressor & Motor': ['reciprocatingcompressor', 'rotarycompressor', 'scrollcompressor', 'motor'],\n",
    "                      'ADVANCED MATERIALS': ['antimicrobial', 'porcelainenamel', 'specialtyglass'] ,\n",
    "                      'Robot': ['lgcloiuv-cbot', 'lgcloiservebot(shelftype)', 'lgcloiservebot(drawertype)', 'lgcloiguidebot'],\n",
    "                      'Others':['etc.','others','other'] \n",
    "                    }\n",
    "\n",
    "def map_product_category(value):\n",
    "    for product, values in product_mapping.items():\n",
    "        if value in values:\n",
    "            return product\n",
    "    return value  # 매핑되지 않은 경우 원래 값을 반환\n",
    "\n",
    "df_train['Product'] = df_train['product_category'].apply(map_product_category)\n",
    "df_test['Product'] = df_test['product_category'].apply(map_product_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451fba7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d5d63d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d5a83c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ac47049",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_rates = df_train.groupby('customer_idx')['is_converted'].mean()* 100\n",
    "df_train['customer_idx'] = df_train['customer_idx'].map(conversion_rates)\n",
    "conversion_rates1 = df_test.groupby('customer_idx')['is_converted'].mean()* 100\n",
    "df_test['customer_idx'] = df_test['customer_idx'].map(conversion_rates1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "274cdb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_rates3 = df_train.groupby('lead_owner')['is_converted'].mean()* 100\n",
    "df_train['lead_owner'] = df_train['lead_owner'].map(conversion_rates3)\n",
    "conversion_rates4 = df_train.groupby('lead_owner')['is_converted'].mean()* 100\n",
    "df_train['lead_owner'] = df_train['lead_owner'].map(conversion_rates4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e920545",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['customer_type'] = df_train['customer_type'].str.lower().str.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c877033",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_type_mapping = { 'End Customer': ['endcustomer','end-user','end-customer','constructioncompany', 'owner/developer', 'medical/healthcarefacility', 'government/publicsector', 'corporate', 'education', 'retail', 'fitness'],\n",
    "                         'Channel Partner' : ['agent','channelpartner', 'distributor','reseller', 'nsp(usonly)', 'nationalreseller', 'regionalreseller', 'si(systemintegrator)', 'proav/avconsultant', 'var(3po)'],\n",
    "                          'Specifier/ Influencer': ['specifier/influencer','architect', 'consultant', 'contractor', 'technical/designfirm', 'regionbuilder', 'installer', 'ad&contentsprovider', 'appliedrep'],\n",
    "                          'Solution Eco-Partner': ['solutioneco-partner','cms/webos/isv', 'mount/metalfabrication','meetingsolution', 'control/processor', 'externalcompute'],\n",
    "                          'Service Partner': ['servicepartner','authorizedservicecenter', 'authorizedservicedealer'], } \n",
    "                          \n",
    "def map_customer_type_category(value):\n",
    "    for customer_type, values in customer_type_mapping.items():\n",
    "        if value in values:\n",
    "            return customer_type\n",
    "    return value  # 매핑되지 않은 경우 원래 값을 반환\n",
    "\n",
    "df_train['customer_type'] = df_train['customer_type'].apply(map_customer_type_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5165ce0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['inquiry_type'] = df_train['inquiry_type'].str.lower().str.replace(\" \", \"\")\n",
    "df_test['inquiry_type'] = df_test['inquiry_type'].str.lower().str.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38999add",
   "metadata": {},
   "outputs": [],
   "source": [
    "continent_mapping = { 'Europe': ['LGEWA', 'LGEMA', 'LGEWR', 'LGEUK', 'LGEFS', 'LGEES', 'LGEEH', 'LGEJE', 'LGEDG', 'LGEIS', 'LGEMK', 'LGEPL', 'LGESW', 'LGEHS', 'LGEAG', 'LGERO', 'LGECZ', 'LGEPT', 'LGEBN', 'LGESC', 'LGELS', 'LGENO','LGEMF'],\n",
    " 'CSI' : ['LGEUA', 'LGEAK','LGERU', 'LGERA', 'LGERI', 'LGERM', 'LGEUR', 'LGELV'], \n",
    " 'China': ['LGETR', 'LGERD', 'LGEHZ', 'LGEND', 'LGEHK', 'LGETT',  'LGEPN', 'LGECH','LGEQH', 'LGESH', 'LGESY', 'LGETA', 'LGEYT', 'LGEKS', 'LGENP', 'LGEHN', 'LGEQD'], \n",
    " 'Asia': ['LGEIL', 'LGSI','LGEAP',  'LGETH', 'LGEVN', 'LGEIN', 'LGESL', 'LGEML', 'LGEJP', 'LGEPH', 'LGEVH','LGEKR'],\n",
    " 'MIDDLE EAST & America': ['LGEEG', 'LGEAT', 'LGESR', 'LGETK', 'LGESA', 'LGEMC', 'LGEGF', 'LGEME', 'LGEOT', 'LGEEC', 'LGENI', 'LGEAF', 'LGELF','LGESJ'],      \n",
    " 'North America': ['LGEMX', 'LGEMM', 'LGEAI', 'LGECI', 'LGEUS', 'LGEMU', 'LGEMS', 'LGEMR'],\n",
    " 'SOUTH & CENTRAL AMERICA' :['LGEAR', 'LGEAZ', 'LGECB', 'LGECL', 'LGEPR', 'LGEPS','LGERS', 'LGESP' ],        \n",
    " }\n",
    "\n",
    " \n",
    "df_train['Continent'] = df_train['response_corporate'].map({value: continent for continent, values in continent_mapping.items() for value in values})\n",
    "df_test['Continent'] = df_test['response_corporate'].map({value: continent for continent, values in continent_mapping.items() for value in values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf09defa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 열의 대체값:\n",
      "{'com_reg_ver_win_rate': 0.09149000306480037, 'historical_existing_cnt': 17.94179198425886, 'ver_win_rate_x': 0.0011425450075443645, 'ver_win_ratio_per_bu': 0.05576048085559978, 'ver_country': 1.603636335312523}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "numeric_columns = df_train.select_dtypes(include='number')\n",
    "\n",
    "columns_without_missing_values = numeric_columns.columns[numeric_columns.isnull().sum() == 0]\n",
    "\n",
    "columns_to_exclude = ['id_strategic_ver', 'it_strategic_ver','idit_strategic_ver']\n",
    "columns_to_exclude.extend(columns_without_missing_values)\n",
    "\n",
    "columns_to_impute = numeric_columns.drop(columns=columns_to_exclude, errors='ignore')\n",
    "\n",
    "imputer = IterativeImputer()\n",
    "\n",
    "df_train_imputed = pd.DataFrame(imputer.fit_transform(columns_to_impute), columns=columns_to_impute.columns)\n",
    "\n",
    "replacement_values = df_train_imputed.mean()\n",
    "print(\"각 열의 대체값:\")\n",
    "print(dict(zip(columns_to_impute.columns, replacement_values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6442b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[columns_to_impute.columns] = df_train[columns_to_impute.columns].fillna(replacement_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3367dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59299 entries, 0 to 59298\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   bant_submit              59299 non-null  float64\n",
      " 1   customer_country         58317 non-null  object \n",
      " 2   business_unit            59299 non-null  object \n",
      " 3   com_reg_ver_win_rate     59299 non-null  float64\n",
      " 4   customer_idx             59299 non-null  float64\n",
      " 5   customer_type            15338 non-null  object \n",
      " 6   enterprise               59299 non-null  object \n",
      " 7   historical_existing_cnt  59299 non-null  float64\n",
      " 8   id_strategic_ver         3444 non-null   float64\n",
      " 9   it_strategic_ver         1121 non-null   float64\n",
      " 10  idit_strategic_ver       4565 non-null   float64\n",
      " 11  customer_job             40566 non-null  object \n",
      " 12  lead_desc_length         59299 non-null  int64  \n",
      " 13  inquiry_type             58358 non-null  object \n",
      " 14  product_category         39925 non-null  object \n",
      " 15  product_subcategory      9235 non-null   object \n",
      " 16  product_modelname        9229 non-null   object \n",
      " 17  customer_country.1       58317 non-null  object \n",
      " 18  customer_position        59299 non-null  object \n",
      " 19  response_corporate       59299 non-null  object \n",
      " 20  expected_timeline        28436 non-null  object \n",
      " 21  ver_cus                  59299 non-null  int64  \n",
      " 22  ver_pro                  59299 non-null  int64  \n",
      " 23  ver_win_rate_x           59299 non-null  float64\n",
      " 24  ver_win_ratio_per_bu     59299 non-null  float64\n",
      " 25  business_area            18417 non-null  object \n",
      " 26  business_subarea         5526 non-null   object \n",
      " 27  lead_owner               59299 non-null  float64\n",
      " 28  is_converted             59299 non-null  bool   \n",
      " 29  Product                  39925 non-null  object \n",
      " 30  ver_country              59299 non-null  float64\n",
      " 31  Continent                59012 non-null  object \n",
      "dtypes: bool(1), float64(11), int64(3), object(17)\n",
      "memory usage: 14.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d20151f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop([\"product_category\",\"customer_country\", \"com_reg_ver_win_rate\", \"id_strategic_ver\",\"it_strategic_ver\", \"idit_strategic_ver\",\"product_subcategory\", \"product_modelname\", \"customer_country.1\",\"response_corporate\",\"business_area\" ,\"business_subarea\",\"ver_cus\",\"ver_pro\"], axis=1)\n",
    "df_test = df_test.drop([\"product_category\",\"customer_country\", \"com_reg_ver_win_rate\", \"id_strategic_ver\",\"it_strategic_ver\", \"idit_strategic_ver\",\"product_subcategory\", \"product_modelname\", \"customer_country.1\",\"response_corporate\",\"business_area\" ,\"business_subarea\",\"ver_cus\",\"ver_pro\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd47e00",
   "metadata": {},
   "source": [
    "### 레이블 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b42b1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoding(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"범주형 데이터를 시리즈 형태로 받아 숫자형 데이터로 변환합니다.\"\"\"\n",
    "\n",
    "    my_dict = {}\n",
    "\n",
    "    # 모든 요소를 문자열로 변환\n",
    "    series = series.astype(str)\n",
    "\n",
    "    for idx, value in enumerate(sorted(series.unique())):\n",
    "        my_dict[value] = idx\n",
    "    series = series.map(my_dict)\n",
    "\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "881a4612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블 인코딩할 칼럼들\n",
    "label_columns = [\n",
    "   #\"customer_country\",\n",
    "    #\"business_subarea\",\n",
    "   # \"business_area\",\n",
    "    \"business_unit\",\n",
    "    \"customer_type\",\n",
    "    \"enterprise\",\n",
    "    \"customer_job\",\n",
    "    \"inquiry_type\",\n",
    "    #\"product_category\",\n",
    "   # \"product_subcategory\",\n",
    "    #\"product_modelname\",\n",
    "   # \"customer_country.1\",\n",
    "    \"customer_position\",\n",
    "    #\"response_corporate\",\n",
    "    \"expected_timeline\",\n",
    "    \"Continent\",\n",
    "    # \"Country\"\n",
    "    \"Product\"\n",
    "]\n",
    "\n",
    "\n",
    "df_all = pd.concat([df_train[label_columns], df_test[label_columns]])\n",
    "\n",
    "for col in label_columns:\n",
    "    df_all[col] = label_encoding(df_all[col])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a477f93",
   "metadata": {},
   "source": [
    "다시 학습 데이터와 제출 데이터를 분리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff10c5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in label_columns:\n",
    "    df_train[col] = df_all.iloc[: len(df_train)][col]\n",
    "    df_test[col] = df_all.iloc[len(df_train) :][col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d332358a",
   "metadata": {},
   "source": [
    "### 2-2. 학습, 검증 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4707ae6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    df_train.drop(\"is_converted\", axis=1),\n",
    "    df_train[\"is_converted\"],\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=400,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ecfa9b",
   "metadata": {},
   "source": [
    "## 3. 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caf257b",
   "metadata": {},
   "source": [
    "### 모델 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4509af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_params = {\n",
    "    'max_depth': (6, 16), \n",
    "    'num_leaves': (24, 64), \n",
    "    'min_child_samples': (10, 200), \n",
    "    'min_child_weight':(1, 50),\n",
    "    'subsample':(0.5, 1.0),\n",
    "    'colsample_bytree': (0.5, 1.0),\n",
    "    'max_bin':(10, 500),\n",
    "    'reg_lambda':(0.001, 10),\n",
    "    'reg_alpha': (0.01, 50) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae0c1bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_f1_eval(max_depth, num_leaves, min_child_samples, min_child_weight, subsample, \n",
    "                colsample_bytree,max_bin, reg_lambda, reg_alpha):\n",
    "    params = {\n",
    "        \"n_estimators\":500, \"learning_rate\":0.02,\n",
    "        'max_depth': int(round(max_depth)), \n",
    "        'num_leaves': int(round(num_leaves)), \n",
    "        'min_child_samples': int(round(min_child_samples)),\n",
    "        'min_child_weight': int(round(min_child_weight)),\n",
    "        'subsample': max(min(subsample, 1), 0), \n",
    "        'colsample_bytree': max(min(colsample_bytree, 1), 0),\n",
    "        'max_bin':  max(int(round(max_bin)),10),\n",
    "        'reg_lambda': max(reg_lambda,0),\n",
    "        'reg_alpha': max(reg_alpha, 0)\n",
    "    }\n",
    "    lgb_model = LGBMClassifier(**params)\n",
    "    lgb_model.fit(x_train, y_train, eval_set=[(x_train, y_train), (x_val, y_val)], eval_metric= 'f1', callbacks = [lgb.early_stopping(stopping_rounds = 100), lgb.log_evaluation(period = 100)],)\n",
    "    valid_pred = lgb_model.predict(x_val)\n",
    "    f1 = f1_score(y_val,valid_pred)\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28c522f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |  max_bin  | max_depth | min_ch... | min_ch... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0407918\tvalid_1's binary_logloss: 0.0416801\n",
      "[200]\ttraining's binary_logloss: 0.0167769\tvalid_1's binary_logloss: 0.0177545\n",
      "[300]\ttraining's binary_logloss: 0.0117689\tvalid_1's binary_logloss: 0.0126404\n",
      "[400]\ttraining's binary_logloss: 0.0105096\tvalid_1's binary_logloss: 0.0113621\n",
      "[500]\ttraining's binary_logloss: 0.0101214\tvalid_1's binary_logloss: 0.0109865\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.0101214\tvalid_1's binary_logloss: 0.0109865\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.974    \u001b[0m | \u001b[0m0.7744   \u001b[0m | \u001b[0m360.4    \u001b[0m | \u001b[0m12.03    \u001b[0m | \u001b[0m113.5    \u001b[0m | \u001b[0m21.76    \u001b[0m | \u001b[0m49.84    \u001b[0m | \u001b[0m21.88    \u001b[0m | \u001b[0m8.918    \u001b[0m | \u001b[0m0.9818   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0417178\tvalid_1's binary_logloss: 0.0424226\n",
      "[200]\ttraining's binary_logloss: 0.0158964\tvalid_1's binary_logloss: 0.0168938\n",
      "[300]\ttraining's binary_logloss: 0.0106876\tvalid_1's binary_logloss: 0.0115724\n",
      "[400]\ttraining's binary_logloss: 0.0098969\tvalid_1's binary_logloss: 0.0108694\n",
      "[500]\ttraining's binary_logloss: 0.00970781\tvalid_1's binary_logloss: 0.0107045\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.00970781\tvalid_1's binary_logloss: 0.0107045\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.974    \u001b[0m | \u001b[0m0.6917   \u001b[0m | \u001b[0m397.9    \u001b[0m | \u001b[0m11.29    \u001b[0m | \u001b[0m117.9    \u001b[0m | \u001b[0m46.35    \u001b[0m | \u001b[0m26.84    \u001b[0m | \u001b[0m4.366    \u001b[0m | \u001b[0m0.2032   \u001b[0m | \u001b[0m0.9163   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0340637\tvalid_1's binary_logloss: 0.0349224\n",
      "[200]\ttraining's binary_logloss: 0.0133147\tvalid_1's binary_logloss: 0.014091\n",
      "[300]\ttraining's binary_logloss: 0.00950207\tvalid_1's binary_logloss: 0.0102468\n",
      "[400]\ttraining's binary_logloss: 0.00872601\tvalid_1's binary_logloss: 0.00957727\n",
      "[500]\ttraining's binary_logloss: 0.00844168\tvalid_1's binary_logloss: 0.00941874\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.00844168\tvalid_1's binary_logloss: 0.00941874\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m0.9745   \u001b[0m | \u001b[95m0.8891   \u001b[0m | \u001b[95m436.3    \u001b[0m | \u001b[95m15.79    \u001b[0m | \u001b[95m161.8    \u001b[0m | \u001b[95m23.61    \u001b[0m | \u001b[95m55.22    \u001b[0m | \u001b[95m5.923    \u001b[0m | \u001b[95m6.4      \u001b[0m | \u001b[95m0.5717   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0331339\tvalid_1's binary_logloss: 0.033721\n",
      "[200]\ttraining's binary_logloss: 0.0146049\tvalid_1's binary_logloss: 0.0153802\n",
      "[300]\ttraining's binary_logloss: 0.0115701\tvalid_1's binary_logloss: 0.0122717\n",
      "[400]\ttraining's binary_logloss: 0.0109694\tvalid_1's binary_logloss: 0.0116839\n",
      "[500]\ttraining's binary_logloss: 0.0108589\tvalid_1's binary_logloss: 0.0115748\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.0108589\tvalid_1's binary_logloss: 0.0115748\n",
      "| \u001b[95m4        \u001b[0m | \u001b[95m0.9755   \u001b[0m | \u001b[95m0.9723   \u001b[0m | \u001b[95m265.7    \u001b[0m | \u001b[95m10.15    \u001b[0m | \u001b[95m60.27    \u001b[0m | \u001b[95m38.94    \u001b[0m | \u001b[95m42.25    \u001b[0m | \u001b[95m28.43    \u001b[0m | \u001b[95m0.1889   \u001b[0m | \u001b[95m0.8088   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0393126\tvalid_1's binary_logloss: 0.0403418\n",
      "[200]\ttraining's binary_logloss: 0.0165537\tvalid_1's binary_logloss: 0.0177442\n",
      "[300]\ttraining's binary_logloss: 0.0123086\tvalid_1's binary_logloss: 0.0133805\n",
      "[400]\ttraining's binary_logloss: 0.011217\tvalid_1's binary_logloss: 0.0122436\n",
      "[500]\ttraining's binary_logloss: 0.0110011\tvalid_1's binary_logloss: 0.0120297\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.0110011\tvalid_1's binary_logloss: 0.0120297\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.9745   \u001b[0m | \u001b[0m0.806    \u001b[0m | \u001b[0m312.3    \u001b[0m | \u001b[0m15.44    \u001b[0m | \u001b[0m139.5    \u001b[0m | \u001b[0m18.62    \u001b[0m | \u001b[0m41.48    \u001b[0m | \u001b[0m34.88    \u001b[0m | \u001b[0m0.6032   \u001b[0m | \u001b[0m0.8334   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0360362\tvalid_1's binary_logloss: 0.0366627\n",
      "[200]\ttraining's binary_logloss: 0.0158666\tvalid_1's binary_logloss: 0.0166874\n",
      "[300]\ttraining's binary_logloss: 0.0121743\tvalid_1's binary_logloss: 0.0129129\n",
      "[400]\ttraining's binary_logloss: 0.011201\tvalid_1's binary_logloss: 0.0118947\n",
      "[500]\ttraining's binary_logloss: 0.0110165\tvalid_1's binary_logloss: 0.0117089\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.0110165\tvalid_1's binary_logloss: 0.0117089\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.975    \u001b[0m | \u001b[0m0.8997   \u001b[0m | \u001b[0m215.3    \u001b[0m | \u001b[0m13.44    \u001b[0m | \u001b[0m51.86    \u001b[0m | \u001b[0m30.69    \u001b[0m | \u001b[0m49.69    \u001b[0m | \u001b[0m32.64    \u001b[0m | \u001b[0m1.463    \u001b[0m | \u001b[0m0.607    \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0334641\tvalid_1's binary_logloss: 0.0340341\n",
      "[200]\ttraining's binary_logloss: 0.0150348\tvalid_1's binary_logloss: 0.0158205\n",
      "[300]\ttraining's binary_logloss: 0.0118394\tvalid_1's binary_logloss: 0.0125478\n",
      "[400]\ttraining's binary_logloss: 0.0111593\tvalid_1's binary_logloss: 0.0118639\n",
      "[500]\ttraining's binary_logloss: 0.0110399\tvalid_1's binary_logloss: 0.0117555\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.0110399\tvalid_1's binary_logloss: 0.0117555\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.9755   \u001b[0m | \u001b[0m0.9752   \u001b[0m | \u001b[0m260.9    \u001b[0m | \u001b[0m13.19    \u001b[0m | \u001b[0m63.06    \u001b[0m | \u001b[0m39.62    \u001b[0m | \u001b[0m39.29    \u001b[0m | \u001b[0m31.04    \u001b[0m | \u001b[0m2.351    \u001b[0m | \u001b[0m0.6457   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0372462\tvalid_1's binary_logloss: 0.0378572\n",
      "[200]\ttraining's binary_logloss: 0.0171963\tvalid_1's binary_logloss: 0.0180843\n",
      "[300]\ttraining's binary_logloss: 0.0133292\tvalid_1's binary_logloss: 0.0141271\n",
      "[400]\ttraining's binary_logloss: 0.0123627\tvalid_1's binary_logloss: 0.0131324\n",
      "[500]\ttraining's binary_logloss: 0.0122403\tvalid_1's binary_logloss: 0.0130198\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.0122403\tvalid_1's binary_logloss: 0.0130198\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.974    \u001b[0m | \u001b[0m0.9037   \u001b[0m | \u001b[0m299.9    \u001b[0m | \u001b[0m11.8     \u001b[0m | \u001b[0m11.26    \u001b[0m | \u001b[0m48.73    \u001b[0m | \u001b[0m45.36    \u001b[0m | \u001b[0m48.27    \u001b[0m | \u001b[0m0.9826   \u001b[0m | \u001b[0m0.9929   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0343065\tvalid_1's binary_logloss: 0.0350972\n",
      "[200]\ttraining's binary_logloss: 0.0134503\tvalid_1's binary_logloss: 0.0142272\n",
      "[300]\ttraining's binary_logloss: 0.00998288\tvalid_1's binary_logloss: 0.010721\n",
      "[400]\ttraining's binary_logloss: 0.00938701\tvalid_1's binary_logloss: 0.0102227\n",
      "[500]\ttraining's binary_logloss: 0.00917447\tvalid_1's binary_logloss: 0.0100299\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.00917447\tvalid_1's binary_logloss: 0.0100299\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.975    \u001b[0m | \u001b[0m0.8547   \u001b[0m | \u001b[0m257.7    \u001b[0m | \u001b[0m6.704    \u001b[0m | \u001b[0m95.15    \u001b[0m | \u001b[0m33.48    \u001b[0m | \u001b[0m59.28    \u001b[0m | \u001b[0m3.038    \u001b[0m | \u001b[0m7.5      \u001b[0m | \u001b[0m0.613    \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0494944\tvalid_1's binary_logloss: 0.0503338\n",
      "[200]\ttraining's binary_logloss: 0.018294\tvalid_1's binary_logloss: 0.0195102\n",
      "[300]\ttraining's binary_logloss: 0.0103492\tvalid_1's binary_logloss: 0.0119028\n",
      "[400]\ttraining's binary_logloss: 0.00746972\tvalid_1's binary_logloss: 0.00929878\n",
      "[500]\ttraining's binary_logloss: 0.00660384\tvalid_1's binary_logloss: 0.00861933\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.00660384\tvalid_1's binary_logloss: 0.00861933\n",
      "| \u001b[95m10       \u001b[0m | \u001b[95m0.9767   \u001b[0m | \u001b[95m0.5495   \u001b[0m | \u001b[95m250.5    \u001b[0m | \u001b[95m14.79    \u001b[0m | \u001b[95m50.6     \u001b[0m | \u001b[95m1.291    \u001b[0m | \u001b[95m25.1     \u001b[0m | \u001b[95m4.036    \u001b[0m | \u001b[95m1.148    \u001b[0m | \u001b[95m0.5809   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.042335\tvalid_1's binary_logloss: 0.0433848\n",
      "[200]\ttraining's binary_logloss: 0.0154346\tvalid_1's binary_logloss: 0.0168219\n",
      "[300]\ttraining's binary_logloss: 0.00885527\tvalid_1's binary_logloss: 0.0105545\n",
      "[400]\ttraining's binary_logloss: 0.00681945\tvalid_1's binary_logloss: 0.00867967\n",
      "[500]\ttraining's binary_logloss: 0.00617348\tvalid_1's binary_logloss: 0.00823227\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.00617348\tvalid_1's binary_logloss: 0.00823227\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.9757   \u001b[0m | \u001b[0m0.6456   \u001b[0m | \u001b[0m247.6    \u001b[0m | \u001b[0m6.509    \u001b[0m | \u001b[0m14.65    \u001b[0m | \u001b[0m2.364    \u001b[0m | \u001b[0m32.56    \u001b[0m | \u001b[0m3.21     \u001b[0m | \u001b[0m3.762    \u001b[0m | \u001b[0m0.5742   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.035735\tvalid_1's binary_logloss: 0.0364202\n",
      "[200]\ttraining's binary_logloss: 0.0123662\tvalid_1's binary_logloss: 0.0134\n",
      "[300]\ttraining's binary_logloss: 0.00799084\tvalid_1's binary_logloss: 0.00948996\n",
      "[400]\ttraining's binary_logloss: 0.00670267\tvalid_1's binary_logloss: 0.00852601\n",
      "[500]\ttraining's binary_logloss: 0.00617846\tvalid_1's binary_logloss: 0.00823048\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.00617846\tvalid_1's binary_logloss: 0.00823048\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.9762   \u001b[0m | \u001b[0m0.8034   \u001b[0m | \u001b[0m281.5    \u001b[0m | \u001b[0m14.01    \u001b[0m | \u001b[0m63.4     \u001b[0m | \u001b[0m3.934    \u001b[0m | \u001b[0m36.11    \u001b[0m | \u001b[0m2.833    \u001b[0m | \u001b[0m6.485    \u001b[0m | \u001b[0m0.9021   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0423666\tvalid_1's binary_logloss: 0.0431311\n",
      "[200]\ttraining's binary_logloss: 0.015516\tvalid_1's binary_logloss: 0.0166478\n",
      "[300]\ttraining's binary_logloss: 0.00889089\tvalid_1's binary_logloss: 0.010492\n",
      "[400]\ttraining's binary_logloss: 0.00681229\tvalid_1's binary_logloss: 0.00882557\n",
      "[500]\ttraining's binary_logloss: 0.00613866\tvalid_1's binary_logloss: 0.00841992\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.00613866\tvalid_1's binary_logloss: 0.00841992\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.9757   \u001b[0m | \u001b[0m0.6435   \u001b[0m | \u001b[0m253.6    \u001b[0m | \u001b[0m9.503    \u001b[0m | \u001b[0m10.93    \u001b[0m | \u001b[0m5.03     \u001b[0m | \u001b[0m25.31    \u001b[0m | \u001b[0m2.947    \u001b[0m | \u001b[0m2.822    \u001b[0m | \u001b[0m0.5921   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0392071\tvalid_1's binary_logloss: 0.0398554\n",
      "[200]\ttraining's binary_logloss: 0.0158702\tvalid_1's binary_logloss: 0.0166238\n",
      "[300]\ttraining's binary_logloss: 0.0115773\tvalid_1's binary_logloss: 0.0122832\n",
      "[400]\ttraining's binary_logloss: 0.0106039\tvalid_1's binary_logloss: 0.0112803\n",
      "[500]\ttraining's binary_logloss: 0.0103613\tvalid_1's binary_logloss: 0.0110271\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.0103613\tvalid_1's binary_logloss: 0.0110271\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.9745   \u001b[0m | \u001b[0m0.8179   \u001b[0m | \u001b[0m14.19    \u001b[0m | \u001b[0m13.37    \u001b[0m | \u001b[0m197.4    \u001b[0m | \u001b[0m7.48     \u001b[0m | \u001b[0m27.33    \u001b[0m | \u001b[0m27.04    \u001b[0m | \u001b[0m0.1989   \u001b[0m | \u001b[0m0.5887   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0484024\tvalid_1's binary_logloss: 0.0492893\n",
      "[200]\ttraining's binary_logloss: 0.0191097\tvalid_1's binary_logloss: 0.0201239\n",
      "[300]\ttraining's binary_logloss: 0.0114482\tvalid_1's binary_logloss: 0.0123945\n",
      "[400]\ttraining's binary_logloss: 0.00906982\tvalid_1's binary_logloss: 0.010086\n",
      "[500]\ttraining's binary_logloss: 0.00842635\tvalid_1's binary_logloss: 0.00952243\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.00842635\tvalid_1's binary_logloss: 0.00952243\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.974    \u001b[0m | \u001b[0m0.5965   \u001b[0m | \u001b[0m258.1    \u001b[0m | \u001b[0m11.57    \u001b[0m | \u001b[0m12.47    \u001b[0m | \u001b[0m9.084    \u001b[0m | \u001b[0m27.12    \u001b[0m | \u001b[0m10.2     \u001b[0m | \u001b[0m1.006    \u001b[0m | \u001b[0m0.9426   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0359943\tvalid_1's binary_logloss: 0.0366812\n",
      "[200]\ttraining's binary_logloss: 0.0126569\tvalid_1's binary_logloss: 0.0135755\n",
      "[300]\ttraining's binary_logloss: 0.00840423\tvalid_1's binary_logloss: 0.00962972\n",
      "[400]\ttraining's binary_logloss: 0.00723411\tvalid_1's binary_logloss: 0.00862842\n",
      "[500]\ttraining's binary_logloss: 0.00682617\tvalid_1's binary_logloss: 0.00835817\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.00682617\tvalid_1's binary_logloss: 0.00835817\n",
      "| \u001b[95m16       \u001b[0m | \u001b[95m0.9767   \u001b[0m | \u001b[95m0.7985   \u001b[0m | \u001b[95m280.8    \u001b[0m | \u001b[95m15.56    \u001b[0m | \u001b[95m57.07    \u001b[0m | \u001b[95m4.054    \u001b[0m | \u001b[95m34.02    \u001b[0m | \u001b[95m5.38     \u001b[0m | \u001b[95m4.095    \u001b[0m | \u001b[95m0.586    \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0356201\tvalid_1's binary_logloss: 0.0363178\n",
      "[200]\ttraining's binary_logloss: 0.0121383\tvalid_1's binary_logloss: 0.0133386\n",
      "[300]\ttraining's binary_logloss: 0.00782005\tvalid_1's binary_logloss: 0.00940389\n",
      "[400]\ttraining's binary_logloss: 0.00654201\tvalid_1's binary_logloss: 0.00851986\n",
      "[500]\ttraining's binary_logloss: 0.00608873\tvalid_1's binary_logloss: 0.00831547\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.00608873\tvalid_1's binary_logloss: 0.00831547\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.9751   \u001b[0m | \u001b[0m0.8435   \u001b[0m | \u001b[0m249.3    \u001b[0m | \u001b[0m10.67    \u001b[0m | \u001b[0m12.66    \u001b[0m | \u001b[0m6.27     \u001b[0m | \u001b[0m24.88    \u001b[0m | \u001b[0m3.205    \u001b[0m | \u001b[0m3.806    \u001b[0m | \u001b[0m0.9283   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0422122\tvalid_1's binary_logloss: 0.0431213\n",
      "[200]\ttraining's binary_logloss: 0.0157076\tvalid_1's binary_logloss: 0.0166606\n",
      "[300]\ttraining's binary_logloss: 0.0102675\tvalid_1's binary_logloss: 0.011267\n",
      "[400]\ttraining's binary_logloss: 0.0085668\tvalid_1's binary_logloss: 0.00966008\n",
      "[500]\ttraining's binary_logloss: 0.00794637\tvalid_1's binary_logloss: 0.00912094\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.00794637\tvalid_1's binary_logloss: 0.00912094\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.9745   \u001b[0m | \u001b[0m0.717    \u001b[0m | \u001b[0m257.5    \u001b[0m | \u001b[0m15.2     \u001b[0m | \u001b[0m49.79    \u001b[0m | \u001b[0m8.598    \u001b[0m | \u001b[0m27.32    \u001b[0m | \u001b[0m7.198    \u001b[0m | \u001b[0m8.799    \u001b[0m | \u001b[0m0.6094   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0328863\tvalid_1's binary_logloss: 0.0337156\n",
      "[200]\ttraining's binary_logloss: 0.0119079\tvalid_1's binary_logloss: 0.013041\n",
      "[300]\ttraining's binary_logloss: 0.00822067\tvalid_1's binary_logloss: 0.00964542\n",
      "[400]\ttraining's binary_logloss: 0.00724343\tvalid_1's binary_logloss: 0.00890189\n",
      "[500]\ttraining's binary_logloss: 0.0068085\tvalid_1's binary_logloss: 0.00867012\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.0068085\tvalid_1's binary_logloss: 0.00867012\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.9757   \u001b[0m | \u001b[0m0.9009   \u001b[0m | \u001b[0m286.6    \u001b[0m | \u001b[0m13.37    \u001b[0m | \u001b[0m53.8     \u001b[0m | \u001b[0m5.602    \u001b[0m | \u001b[0m35.79    \u001b[0m | \u001b[0m5.162    \u001b[0m | \u001b[0m5.233    \u001b[0m | \u001b[0m0.9596   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0324625\tvalid_1's binary_logloss: 0.0331686\n",
      "[200]\ttraining's binary_logloss: 0.0116411\tvalid_1's binary_logloss: 0.0127622\n",
      "[300]\ttraining's binary_logloss: 0.0079762\tvalid_1's binary_logloss: 0.0094781\n",
      "[400]\ttraining's binary_logloss: 0.00697836\tvalid_1's binary_logloss: 0.00874425\n",
      "[500]\ttraining's binary_logloss: 0.00653673\tvalid_1's binary_logloss: 0.00851569\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.00653673\tvalid_1's binary_logloss: 0.00851569\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.9746   \u001b[0m | \u001b[0m0.897    \u001b[0m | \u001b[0m278.0    \u001b[0m | \u001b[0m11.71    \u001b[0m | \u001b[0m59.43    \u001b[0m | \u001b[0m5.493    \u001b[0m | \u001b[0m30.15    \u001b[0m | \u001b[0m4.593    \u001b[0m | \u001b[0m4.328    \u001b[0m | \u001b[0m0.7537   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0485478\tvalid_1's binary_logloss: 0.0493693\n",
      "[200]\ttraining's binary_logloss: 0.0191119\tvalid_1's binary_logloss: 0.0201516\n",
      "[300]\ttraining's binary_logloss: 0.0113859\tvalid_1's binary_logloss: 0.0123973\n",
      "[400]\ttraining's binary_logloss: 0.0089802\tvalid_1's binary_logloss: 0.0100852\n",
      "[500]\ttraining's binary_logloss: 0.00829483\tvalid_1's binary_logloss: 0.00947647\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.00829483\tvalid_1's binary_logloss: 0.00947647\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.9751   \u001b[0m | \u001b[0m0.599    \u001b[0m | \u001b[0m248.3    \u001b[0m | \u001b[0m15.53    \u001b[0m | \u001b[0m47.35    \u001b[0m | \u001b[0m1.289    \u001b[0m | \u001b[0m24.06    \u001b[0m | \u001b[0m9.969    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m0.5084   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.036117\tvalid_1's binary_logloss: 0.0366762\n",
      "[200]\ttraining's binary_logloss: 0.0159198\tvalid_1's binary_logloss: 0.0166938\n",
      "[300]\ttraining's binary_logloss: 0.0121713\tvalid_1's binary_logloss: 0.0128573\n",
      "[400]\ttraining's binary_logloss: 0.011177\tvalid_1's binary_logloss: 0.0118208\n",
      "[500]\ttraining's binary_logloss: 0.0109665\tvalid_1's binary_logloss: 0.0116193\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.0109665\tvalid_1's binary_logloss: 0.0116193\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.975    \u001b[0m | \u001b[0m0.877    \u001b[0m | \u001b[0m260.7    \u001b[0m | \u001b[0m11.73    \u001b[0m | \u001b[0m61.99    \u001b[0m | \u001b[0m36.99    \u001b[0m | \u001b[0m42.56    \u001b[0m | \u001b[0m30.04    \u001b[0m | \u001b[0m3.857    \u001b[0m | \u001b[0m0.6211   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0346665\tvalid_1's binary_logloss: 0.0352208\n",
      "[200]\ttraining's binary_logloss: 0.0162537\tvalid_1's binary_logloss: 0.0170306\n",
      "[300]\ttraining's binary_logloss: 0.0128123\tvalid_1's binary_logloss: 0.0135239\n",
      "[400]\ttraining's binary_logloss: 0.0120059\tvalid_1's binary_logloss: 0.0126798\n",
      "[500]\ttraining's binary_logloss: 0.0119585\tvalid_1's binary_logloss: 0.0126347\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.0119585\tvalid_1's binary_logloss: 0.0126347\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.9755   \u001b[0m | \u001b[0m0.9707   \u001b[0m | \u001b[0m151.7    \u001b[0m | \u001b[0m13.38    \u001b[0m | \u001b[0m46.18    \u001b[0m | \u001b[0m37.89    \u001b[0m | \u001b[0m38.31    \u001b[0m | \u001b[0m47.9     \u001b[0m | \u001b[0m5.181    \u001b[0m | \u001b[0m0.5227   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0392502\tvalid_1's binary_logloss: 0.0402571\n",
      "[200]\ttraining's binary_logloss: 0.0161463\tvalid_1's binary_logloss: 0.0172508\n",
      "[300]\ttraining's binary_logloss: 0.011744\tvalid_1's binary_logloss: 0.012736\n",
      "[400]\ttraining's binary_logloss: 0.010647\tvalid_1's binary_logloss: 0.0115947\n",
      "[500]\ttraining's binary_logloss: 0.0103139\tvalid_1's binary_logloss: 0.0112458\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.0103139\tvalid_1's binary_logloss: 0.0112458\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.974    \u001b[0m | \u001b[0m0.8324   \u001b[0m | \u001b[0m52.63    \u001b[0m | \u001b[0m14.54    \u001b[0m | \u001b[0m100.8    \u001b[0m | \u001b[0m22.84    \u001b[0m | \u001b[0m59.28    \u001b[0m | \u001b[0m25.3     \u001b[0m | \u001b[0m7.74     \u001b[0m | \u001b[0m0.9656   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0318272\tvalid_1's binary_logloss: 0.0323458\n",
      "[200]\ttraining's binary_logloss: 0.0121546\tvalid_1's binary_logloss: 0.0129146\n",
      "[300]\ttraining's binary_logloss: 0.00880853\tvalid_1's binary_logloss: 0.00977276\n",
      "[400]\ttraining's binary_logloss: 0.00796633\tvalid_1's binary_logloss: 0.00913779\n",
      "[500]\ttraining's binary_logloss: 0.00773631\tvalid_1's binary_logloss: 0.00900503\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.00773631\tvalid_1's binary_logloss: 0.00900503\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.9751   \u001b[0m | \u001b[0m0.9405   \u001b[0m | \u001b[0m280.5    \u001b[0m | \u001b[0m13.39    \u001b[0m | \u001b[0m56.44    \u001b[0m | \u001b[0m4.459    \u001b[0m | \u001b[0m39.37    \u001b[0m | \u001b[0m9.345    \u001b[0m | \u001b[0m5.571    \u001b[0m | \u001b[0m0.7011   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0336231\tvalid_1's binary_logloss: 0.0346601\n",
      "[200]\ttraining's binary_logloss: 0.0106618\tvalid_1's binary_logloss: 0.0125732\n",
      "[300]\ttraining's binary_logloss: 0.00630768\tvalid_1's binary_logloss: 0.00898732\n",
      "[400]\ttraining's binary_logloss: 0.00498874\tvalid_1's binary_logloss: 0.00826604\n",
      "[500]\ttraining's binary_logloss: 0.00452661\tvalid_1's binary_logloss: 0.00824653\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.00452661\tvalid_1's binary_logloss: 0.00824653\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m0.9751   \u001b[0m | \u001b[0m0.8442   \u001b[0m | \u001b[0m281.0    \u001b[0m | \u001b[0m14.9     \u001b[0m | \u001b[0m50.24    \u001b[0m | \u001b[0m1.425    \u001b[0m | \u001b[0m35.77    \u001b[0m | \u001b[0m1.892    \u001b[0m | \u001b[0m0.6645   \u001b[0m | \u001b[0m0.6917   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0509275\tvalid_1's binary_logloss: 0.0518653\n",
      "[200]\ttraining's binary_logloss: 0.0195245\tvalid_1's binary_logloss: 0.0207031\n",
      "[300]\ttraining's binary_logloss: 0.0115094\tvalid_1's binary_logloss: 0.0127492\n",
      "[400]\ttraining's binary_logloss: 0.00853989\tvalid_1's binary_logloss: 0.00994249\n",
      "[500]\ttraining's binary_logloss: 0.00756677\tvalid_1's binary_logloss: 0.00913684\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.00756677\tvalid_1's binary_logloss: 0.00913684\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m0.9762   \u001b[0m | \u001b[0m0.5105   \u001b[0m | \u001b[0m286.4    \u001b[0m | \u001b[0m13.35    \u001b[0m | \u001b[0m61.02    \u001b[0m | \u001b[0m1.851    \u001b[0m | \u001b[0m39.55    \u001b[0m | \u001b[0m4.585    \u001b[0m | \u001b[0m9.213    \u001b[0m | \u001b[0m0.8277   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0406829\tvalid_1's binary_logloss: 0.0414614\n",
      "[200]\ttraining's binary_logloss: 0.0144364\tvalid_1's binary_logloss: 0.015486\n",
      "[300]\ttraining's binary_logloss: 0.00889204\tvalid_1's binary_logloss: 0.0103322\n",
      "[400]\ttraining's binary_logloss: 0.00711541\tvalid_1's binary_logloss: 0.00888032\n",
      "[500]\ttraining's binary_logloss: 0.00646269\tvalid_1's binary_logloss: 0.0084867\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.00646269\tvalid_1's binary_logloss: 0.0084867\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m0.9746   \u001b[0m | \u001b[0m0.7088   \u001b[0m | \u001b[0m275.0    \u001b[0m | \u001b[0m10.13    \u001b[0m | \u001b[0m62.06    \u001b[0m | \u001b[0m9.473    \u001b[0m | \u001b[0m39.46    \u001b[0m | \u001b[0m1.826    \u001b[0m | \u001b[0m7.38     \u001b[0m | \u001b[0m0.5874   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0372327\tvalid_1's binary_logloss: 0.0380202\n",
      "[200]\ttraining's binary_logloss: 0.0138715\tvalid_1's binary_logloss: 0.0146742\n",
      "[300]\ttraining's binary_logloss: 0.00970145\tvalid_1's binary_logloss: 0.0105614\n",
      "[400]\ttraining's binary_logloss: 0.00857031\tvalid_1's binary_logloss: 0.00955137\n",
      "[500]\ttraining's binary_logloss: 0.00827897\tvalid_1's binary_logloss: 0.0093417\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.00827897\tvalid_1's binary_logloss: 0.0093417\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m0.9741   \u001b[0m | \u001b[0m0.8176   \u001b[0m | \u001b[0m286.0    \u001b[0m | \u001b[0m12.3     \u001b[0m | \u001b[0m54.08    \u001b[0m | \u001b[0m2.357    \u001b[0m | \u001b[0m38.15    \u001b[0m | \u001b[0m11.65    \u001b[0m | \u001b[0m5.988    \u001b[0m | \u001b[0m0.6508   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.048676\tvalid_1's binary_logloss: 0.0491434\n",
      "[200]\ttraining's binary_logloss: 0.0218346\tvalid_1's binary_logloss: 0.0226727\n",
      "[300]\ttraining's binary_logloss: 0.0150944\tvalid_1's binary_logloss: 0.0160133\n",
      "[400]\ttraining's binary_logloss: 0.0129435\tvalid_1's binary_logloss: 0.0138524\n",
      "[500]\ttraining's binary_logloss: 0.012435\tvalid_1's binary_logloss: 0.0133563\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.012435\tvalid_1's binary_logloss: 0.0133563\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m0.9745   \u001b[0m | \u001b[0m0.6595   \u001b[0m | \u001b[0m152.8    \u001b[0m | \u001b[0m12.69    \u001b[0m | \u001b[0m41.34    \u001b[0m | \u001b[0m30.66    \u001b[0m | \u001b[0m38.18    \u001b[0m | \u001b[0m49.77    \u001b[0m | \u001b[0m7.545    \u001b[0m | \u001b[0m0.8533   \u001b[0m |\n",
      "=====================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "lgbBO = BayesianOptimization(lgb_f1_eval,bayesian_params , random_state=0)\n",
    "lgbBO.maximize(init_points=5, n_iter=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f536672f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9739500265816055, 0.9739500265816055, 0.9745222929936306, 0.975531914893617, 0.974468085106383, 0.9750132908027644, 0.9755058572949946, 0.9739500265816055, 0.9750132908027644, 0.9767195767195767, 0.9756613756613757, 0.9762030671602326, 0.9756871035940804, 0.9744952178533475, 0.9739500265816055, 0.9767441860465116, 0.9751454257006875, 0.9745493107104984, 0.9756613756613757, 0.9746031746031746, 0.9750663129973474, 0.9749866950505588, 0.9755058572949946, 0.9739776951672862, 0.9751454257006875, 0.9751191106405506, 0.9761526232114468, 0.9746300211416491, 0.9740603493912122, 0.9744952178533475]\n",
      "maximum target index: 15\n"
     ]
    }
   ],
   "source": [
    "target_list = []\n",
    "for result in lgbBO.res:\n",
    "    target = result['target']\n",
    "    target_list.append(target)\n",
    "print(target_list)\n",
    "# 가장 큰 target 값을 가지는 순번(index)를 추출\n",
    "print('maximum target index:', np.argmax(np.array(target_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0293462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': 0.9767441860465116, 'params': {'colsample_bytree': 0.7984694893597473, 'max_bin': 280.8125538867223, 'max_depth': 15.561555833121675, 'min_child_samples': 57.07249223589623, 'min_child_weight': 4.053589307787831, 'num_leaves': 34.01763477561242, 'reg_alpha': 5.379945877221973, 'reg_lambda': 4.094651011509741, 'subsample': 0.5859549044680197}}\n"
     ]
    }
   ],
   "source": [
    "max_dict = lgbBO.res[np.argmax(np.array(target_list))]\n",
    "print(max_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "910a71a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_apps_all(df_train):\n",
    "    ftr_app = df_train.drop(\"is_converted\", axis=1)\n",
    "    target_app = df_train[\"is_converted\"]\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(ftr_app, target_app, test_size=0.2, shuffle=True, random_state=400)\n",
    "    print('train shape:', train_x.shape, 'valid shape:', valid_x.shape)\n",
    "    clf = LGBMClassifier(\n",
    "                nthread=4,\n",
    "                n_estimators=1000,\n",
    "                learning_rate=0.02,\n",
    "                max_depth = 15,\n",
    "                num_leaves=34,\n",
    "                colsample_bytree=0.7984,\n",
    "                subsample=0.5859,\n",
    "                max_bin=280,\n",
    "                reg_alpha=5.3799,\n",
    "                reg_lambda=4.094,\n",
    "                min_child_weight=4,\n",
    "                min_child_samples=57,\n",
    "                silent=-1,\n",
    "                verbose=-1,\n",
    "                )\n",
    "\n",
    "    clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'f1', callbacks = [lgb.early_stopping(stopping_rounds = 100), lgb.log_evaluation(period = 100)])\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacd5ed8",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "766d1980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (47439, 17) valid shape: (11860, 17)\n",
      "[LightGBM] [Warning] num_threads is set with nthread=4, will be overridden by n_jobs=-1. Current value: num_threads=-1\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's binary_logloss: 0.0359942\tvalid_1's binary_logloss: 0.0366811\n",
      "[200]\ttraining's binary_logloss: 0.0126568\tvalid_1's binary_logloss: 0.0135755\n",
      "[300]\ttraining's binary_logloss: 0.00840412\tvalid_1's binary_logloss: 0.00962959\n",
      "[400]\ttraining's binary_logloss: 0.00723403\tvalid_1's binary_logloss: 0.00862832\n",
      "[500]\ttraining's binary_logloss: 0.00682124\tvalid_1's binary_logloss: 0.00835666\n",
      "[600]\ttraining's binary_logloss: 0.00660564\tvalid_1's binary_logloss: 0.00825543\n",
      "[700]\ttraining's binary_logloss: 0.00654141\tvalid_1's binary_logloss: 0.00821787\n",
      "[800]\ttraining's binary_logloss: 0.00649856\tvalid_1's binary_logloss: 0.00820343\n",
      "[900]\ttraining's binary_logloss: 0.00649367\tvalid_1's binary_logloss: 0.00820284\n",
      "Early stopping, best iteration is:\n",
      "[813]\ttraining's binary_logloss: 0.00649593\tvalid_1's binary_logloss: 0.00820265\n"
     ]
    }
   ],
   "source": [
    "clf = train_apps_all(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf2de5f",
   "metadata": {},
   "source": [
    "### 모델 성능 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8871444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, y_pred=None):\n",
    "    confusion = confusion_matrix(y_test, y_pred, labels=[True, False])\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, labels=[True, False])\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    F1 = f1_score(y_test, y_pred, labels=[True, False])\n",
    "\n",
    "    print(\"오차행렬:\\n\", confusion)\n",
    "    print(\"\\n정확도: {:.4f}\".format(accuracy))\n",
    "    print(\"정밀도: {:.4f}\".format(precision))\n",
    "    print(\"재현율: {:.4f}\".format(recall))\n",
    "    print(\"F1: {:.4f}\".format(F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56a86373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬:\n",
      " [[  924    23]\n",
      " [   21 10892]]\n",
      "\n",
      "정확도: 0.9963\n",
      "정밀도: 0.9778\n",
      "재현율: 0.9757\n",
      "F1: 0.9767\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(x_val)\n",
    "get_clf_eval(y_val, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adf8300",
   "metadata": {},
   "source": [
    "\n",
    "## 4. 제출하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0b6e17",
   "metadata": {},
   "source": [
    "### 테스트 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43daa73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측에 필요한 데이터 분리\n",
    "x_test = df_test.drop([\"is_converted\", \"id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d13f7a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1410"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = clf.predict(x_test)\n",
    "sum(test_pred) # True로 예측된 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f18e6a",
   "metadata": {},
   "source": [
    "### 제출 파일 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3128a458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
    "df_sub = pd.read_csv(\"submission.csv\")\n",
    "df_sub[\"is_converted\"] = test_pred\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7867ce",
   "metadata": {},
   "source": [
    "**우측 상단의 제출 버튼을 클릭해 결과를 확인하세요**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
